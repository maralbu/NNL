{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pennylane import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane.templates.embeddings import AngleEmbedding, AmplitudeEmbedding\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('grib_data.csv', sep=',')\n",
    "\n",
    "# Convert datetime columns to numeric (e.g., Unix timestamp)\n",
    "def convert_to_numeric(df, column_name):\n",
    "    df[column_name] = pd.to_datetime(df[column_name], errors='coerce').astype(np.int64) / 1e9  # Convert to Unix timestamp\n",
    "\n",
    "# Convert relevant columns\n",
    "for col in ['time', 'step', 'valid_time']:\n",
    "    convert_to_numeric(df, col)\n",
    "\n",
    "# Convert all columns to float\n",
    "df = df.astype(float)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train, test = train_test_split(df, test_size=0.30, random_state=2)\n",
    "\n",
    "# Sample the datasets\n",
    "train_set = train.sample(160, random_state=42)\n",
    "test_set = test.sample(40, random_state=42)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 359775 entries, 0 to 359774\n",
      "Data columns (total 70 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   time                 359775 non-null  float64\n",
      " 1   latitude             359775 non-null  float64\n",
      " 2   longitude            359775 non-null  float64\n",
      " 3   number               359775 non-null  float64\n",
      " 4   step                 359775 non-null  float64\n",
      " 5   surface              359775 non-null  float64\n",
      " 6   valid_time           359775 non-null  float64\n",
      " 7   u100                 359775 non-null  float64\n",
      " 8   v100                 359775 non-null  float64\n",
      " 9   u10n                 359775 non-null  float64\n",
      " 10  u10                  359775 non-null  float64\n",
      " 11  v10n                 359775 non-null  float64\n",
      " 12  v10                  359775 non-null  float64\n",
      " 13  d2m                  359775 non-null  float64\n",
      " 14  t2m                  359775 non-null  float64\n",
      " 15  meanSea              359775 non-null  float64\n",
      " 16  anor                 359775 non-null  float64\n",
      " 17  isor                 359775 non-null  float64\n",
      " 18  blh                  359775 non-null  float64\n",
      " 19  chnk                 359775 non-null  float64\n",
      " 20  heightAboveGround    359775 non-null  float64\n",
      " 21  cape                 359775 non-null  float64\n",
      " 22  fal                  359775 non-null  float64\n",
      " 23  flsr                 359775 non-null  float64\n",
      " 24  fsr                  359775 non-null  float64\n",
      " 25  z                    359775 non-null  float64\n",
      " 26  hcc                  359775 non-null  float64\n",
      " 27  cvh                  359775 non-null  float64\n",
      " 28  depthBelowLandLayer  359775 non-null  float64\n",
      " 29  istl1                359775 non-null  float64\n",
      " 30  iews                 359775 non-null  float64\n",
      " 31  ie                   359775 non-null  float64\n",
      " 32  inss                 359775 non-null  float64\n",
      " 33  ishf                 359775 non-null  float64\n",
      " 34  lblt                 359775 non-null  float64\n",
      " 35  cl                   359775 non-null  float64\n",
      " 36  dl                   359775 non-null  float64\n",
      " 37  licd                 359775 non-null  float64\n",
      " 38  lict                 359775 non-null  float64\n",
      " 39  lmld                 359775 non-null  float64\n",
      " 40  lmlt                 359775 non-null  float64\n",
      " 41  lshf                 359775 non-null  float64\n",
      " 42  ltlt                 359775 non-null  float64\n",
      " 43  lsm                  359775 non-null  float64\n",
      " 44  lai_hv               359775 non-null  float64\n",
      " 45  lai_lv               359775 non-null  float64\n",
      " 46  lcc                  359775 non-null  float64\n",
      " 47  cvl                  359775 non-null  float64\n",
      " 48  msl                  359775 non-null  float64\n",
      " 49  mcc                  359775 non-null  float64\n",
      " 50  alnid                359775 non-null  float64\n",
      " 51  alnip                359775 non-null  float64\n",
      " 52  siconc               126725 non-null  float64\n",
      " 53  sst                  126725 non-null  float64\n",
      " 54  src                  359775 non-null  float64\n",
      " 55  skt                  359775 non-null  float64\n",
      " 56  slor                 359775 non-null  float64\n",
      " 57  asn                  359775 non-null  float64\n",
      " 58  rsn                  359775 non-null  float64\n",
      " 59  sd                   359775 non-null  float64\n",
      " 60  stl1                 359775 non-null  float64\n",
      " 61  slt                  359775 non-null  float64\n",
      " 62  sdfor                359775 non-null  float64\n",
      " 63  sdor                 359775 non-null  float64\n",
      " 64  sp                   359775 non-null  float64\n",
      " 65  tsn                  359775 non-null  float64\n",
      " 66  tcc                  359775 non-null  float64\n",
      " 67  tciw                 359775 non-null  float64\n",
      " 68  tclw                 359775 non-null  float64\n",
      " 69  tco3                 359775 non-null  float64\n",
      "dtypes: float64(70)\n",
      "memory usage: 192.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>number</th>\n",
       "      <th>step</th>\n",
       "      <th>surface</th>\n",
       "      <th>valid_time</th>\n",
       "      <th>u100</th>\n",
       "      <th>v100</th>\n",
       "      <th>u10n</th>\n",
       "      <th>...</th>\n",
       "      <th>stl1</th>\n",
       "      <th>slt</th>\n",
       "      <th>sdfor</th>\n",
       "      <th>sdor</th>\n",
       "      <th>sp</th>\n",
       "      <th>tsn</th>\n",
       "      <th>tcc</th>\n",
       "      <th>tciw</th>\n",
       "      <th>tclw</th>\n",
       "      <th>tco3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.597750e+05</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>359775.0</td>\n",
       "      <td>3.597750e+05</td>\n",
       "      <td>359775.0</td>\n",
       "      <td>3.597750e+05</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>359775.000000</td>\n",
       "      <td>359775.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.705108e+09</td>\n",
       "      <td>21.990000</td>\n",
       "      <td>82.670000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.223372e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.705108e+09</td>\n",
       "      <td>-1.389359</td>\n",
       "      <td>-1.447951</td>\n",
       "      <td>-1.265897</td>\n",
       "      <td>...</td>\n",
       "      <td>285.773462</td>\n",
       "      <td>1.889584</td>\n",
       "      <td>67.941117</td>\n",
       "      <td>94.489307</td>\n",
       "      <td>89724.177824</td>\n",
       "      <td>276.160228</td>\n",
       "      <td>0.418842</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.026459</td>\n",
       "      <td>0.005839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.230401e+05</td>\n",
       "      <td>8.876479</td>\n",
       "      <td>8.443451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587298e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.230401e+05</td>\n",
       "      <td>2.909469</td>\n",
       "      <td>2.929684</td>\n",
       "      <td>2.141267</td>\n",
       "      <td>...</td>\n",
       "      <td>16.737633</td>\n",
       "      <td>1.581977</td>\n",
       "      <td>112.114888</td>\n",
       "      <td>147.960510</td>\n",
       "      <td>17612.564356</td>\n",
       "      <td>22.047783</td>\n",
       "      <td>0.378391</td>\n",
       "      <td>0.027872</td>\n",
       "      <td>0.060537</td>\n",
       "      <td>0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.704071e+09</td>\n",
       "      <td>6.740000</td>\n",
       "      <td>68.170000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.223372e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.704071e+09</td>\n",
       "      <td>-13.360776</td>\n",
       "      <td>-12.394982</td>\n",
       "      <td>-11.429073</td>\n",
       "      <td>...</td>\n",
       "      <td>241.089450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48842.492000</td>\n",
       "      <td>223.589070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.704589e+09</td>\n",
       "      <td>14.240000</td>\n",
       "      <td>75.420000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.223372e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.704589e+09</td>\n",
       "      <td>-3.436470</td>\n",
       "      <td>-3.569078</td>\n",
       "      <td>-2.226872</td>\n",
       "      <td>...</td>\n",
       "      <td>276.682680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86302.818000</td>\n",
       "      <td>272.347230</td>\n",
       "      <td>0.029724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.705108e+09</td>\n",
       "      <td>21.990000</td>\n",
       "      <td>82.670000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.223372e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.705108e+09</td>\n",
       "      <td>-1.179940</td>\n",
       "      <td>-1.237203</td>\n",
       "      <td>-0.480583</td>\n",
       "      <td>...</td>\n",
       "      <td>290.270630</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.004761</td>\n",
       "      <td>20.667542</td>\n",
       "      <td>99471.280000</td>\n",
       "      <td>273.161070</td>\n",
       "      <td>0.322571</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.005592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.705626e+09</td>\n",
       "      <td>29.740000</td>\n",
       "      <td>89.920000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.223372e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.705626e+09</td>\n",
       "      <td>0.523396</td>\n",
       "      <td>0.577265</td>\n",
       "      <td>0.125910</td>\n",
       "      <td>...</td>\n",
       "      <td>300.553815</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>88.463560</td>\n",
       "      <td>130.827580</td>\n",
       "      <td>101245.766000</td>\n",
       "      <td>300.468020</td>\n",
       "      <td>0.816681</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.027557</td>\n",
       "      <td>0.006239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.706144e+09</td>\n",
       "      <td>37.240000</td>\n",
       "      <td>97.170000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.223372e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.706144e+09</td>\n",
       "      <td>12.678922</td>\n",
       "      <td>9.792582</td>\n",
       "      <td>7.389265</td>\n",
       "      <td>...</td>\n",
       "      <td>303.333280</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>692.202330</td>\n",
       "      <td>923.084700</td>\n",
       "      <td>102031.625000</td>\n",
       "      <td>303.332950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.421082</td>\n",
       "      <td>1.204315</td>\n",
       "      <td>0.009016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time       latitude      longitude    number          step  \\\n",
       "count  3.597750e+05  359775.000000  359775.000000  359775.0  3.597750e+05   \n",
       "mean   1.705108e+09      21.990000      82.670000       0.0 -9.223372e+09   \n",
       "std    6.230401e+05       8.876479       8.443451       0.0  1.587298e-02   \n",
       "min    1.704071e+09       6.740000      68.170000       0.0 -9.223372e+09   \n",
       "25%    1.704589e+09      14.240000      75.420000       0.0 -9.223372e+09   \n",
       "50%    1.705108e+09      21.990000      82.670000       0.0 -9.223372e+09   \n",
       "75%    1.705626e+09      29.740000      89.920000       0.0 -9.223372e+09   \n",
       "max    1.706144e+09      37.240000      97.170000       0.0 -9.223372e+09   \n",
       "\n",
       "        surface    valid_time           u100           v100           u10n  \\\n",
       "count  359775.0  3.597750e+05  359775.000000  359775.000000  359775.000000   \n",
       "mean        0.0  1.705108e+09      -1.389359      -1.447951      -1.265897   \n",
       "std         0.0  6.230401e+05       2.909469       2.929684       2.141267   \n",
       "min         0.0  1.704071e+09     -13.360776     -12.394982     -11.429073   \n",
       "25%         0.0  1.704589e+09      -3.436470      -3.569078      -2.226872   \n",
       "50%         0.0  1.705108e+09      -1.179940      -1.237203      -0.480583   \n",
       "75%         0.0  1.705626e+09       0.523396       0.577265       0.125910   \n",
       "max         0.0  1.706144e+09      12.678922       9.792582       7.389265   \n",
       "\n",
       "       ...           stl1            slt          sdfor           sdor  \\\n",
       "count  ...  359775.000000  359775.000000  359775.000000  359775.000000   \n",
       "mean   ...     285.773462       1.889584      67.941117      94.489307   \n",
       "std    ...      16.737633       1.581977     112.114888     147.960510   \n",
       "min    ...     241.089450       0.000000       0.000000       0.000000   \n",
       "25%    ...     276.682680       0.000000       0.000000       0.000000   \n",
       "50%    ...     290.270630       2.000000      12.004761      20.667542   \n",
       "75%    ...     300.553815       3.000000      88.463560     130.827580   \n",
       "max    ...     303.333280       7.000000     692.202330     923.084700   \n",
       "\n",
       "                  sp            tsn            tcc           tciw  \\\n",
       "count  359775.000000  359775.000000  359775.000000  359775.000000   \n",
       "mean    89724.177824     276.160228       0.418842       0.005182   \n",
       "std     17612.564356      22.047783       0.378391       0.027872   \n",
       "min     48842.492000     223.589070       0.000000       0.000000   \n",
       "25%     86302.818000     272.347230       0.029724       0.000000   \n",
       "50%     99471.280000     273.161070       0.322571       0.000004   \n",
       "75%    101245.766000     300.468020       0.816681       0.000853   \n",
       "max    102031.625000     303.332950       1.000000       1.421082   \n",
       "\n",
       "                tclw           tco3  \n",
       "count  359775.000000  359775.000000  \n",
       "mean        0.026459       0.005839  \n",
       "std         0.060537       0.000687  \n",
       "min         0.000000       0.004930  \n",
       "25%         0.000000       0.005292  \n",
       "50%         0.002869       0.005592  \n",
       "75%         0.027557       0.006239  \n",
       "max         1.204315       0.009016  \n",
       "\n",
       "[8 rows x 70 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_set)\n",
    "X_test = scaler.transform(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane.templates import AngleEmbedding\n",
    "\n",
    "# Define a quantum device\n",
    "dev = qml.device(\"default.qubit\", wires=4)\n",
    "\n",
    "# Define a quantum node\n",
    "@qml.qnode(dev)\n",
    "def quantum_model(params, x):\n",
    "    AngleEmbedding(x, wires=[0, 1, 2, 3])\n",
    "    qml.templates.layers.BasicEntanglerLayers(params, wires=[0, 1, 2, 3])\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "# Example function to get quantum predictions\n",
    "def get_predictions(X):\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        params = np.random.rand(3, 4)  # Example: Random params, adjust as necessary\n",
    "        pred = quantum_model(params, x)\n",
    "        predictions.append(pred)\n",
    "    return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train anomalies latitude/longitude shape: (8, 2)\n",
      "Train confidence shape: (8,)\n",
      "Test anomalies latitude/longitude shape: (0, 2)\n",
      "Test confidence shape: (0,)\n",
      "Train anomalies:\n",
      "Anomaly 1: Latitude=8.490000000000002, Longitude=75.67, Confidence=0.9984\n",
      "Anomaly 2: Latitude=29.24, Longitude=90.92, Confidence=0.9995\n",
      "Anomaly 3: Latitude=35.24, Longitude=93.42, Confidence=0.9977\n",
      "Anomaly 4: Latitude=29.74, Longitude=88.67, Confidence=0.9975\n",
      "Anomaly 5: Latitude=7.490000000000002, Longitude=70.17, Confidence=0.9971\n",
      "Anomaly 6: Latitude=16.240000000000002, Longitude=69.42, Confidence=1.0000\n",
      "Anomaly 7: Latitude=7.240000000000002, Longitude=85.92, Confidence=0.9987\n",
      "Anomaly 8: Latitude=28.74, Longitude=92.17, Confidence=0.9974\n",
      "\n",
      "Test anomalies:\n",
      "\n",
      "Execution time: 6.90 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from pennylane import QNode, Hadamard, CNOT, RX, RZ, Z\n",
    "from pennylane.templates import AngleEmbedding\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time\n",
    "\n",
    "# Measure time to track execution\n",
    "start = time.time()\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('grib_data.csv', sep=',')\n",
    "\n",
    "# Convert datetime columns to numeric (e.g., Unix timestamp)\n",
    "def convert_to_numeric(df, column_name):\n",
    "    df[column_name] = pd.to_datetime(df[column_name], errors='coerce').astype(np.int64) / 1e9  # Convert to Unix timestamp\n",
    "\n",
    "# Convert relevant columns\n",
    "for col in ['time', 'step', 'valid_time']:\n",
    "    convert_to_numeric(df, col)\n",
    "\n",
    "# Convert all columns to float\n",
    "df = df.astype(float)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')  # You can also use other strategies like median or most_frequent\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train, test = train_test_split(df_imputed, test_size=0.30, random_state=2)\n",
    "\n",
    "# Sample the datasets\n",
    "train_set = train.sample(160, random_state=42)\n",
    "test_set = test.sample(40, random_state=42)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_set.drop(columns=['latitude', 'longitude']))\n",
    "X_test = scaler.transform(test_set.drop(columns=['latitude', 'longitude']))\n",
    "\n",
    "# Extract latitude and longitude for anomalies\n",
    "lat_train = train_set[['latitude', 'longitude']].values\n",
    "lat_test = test_set[['latitude', 'longitude']].values\n",
    "\n",
    "# Number of qubits\n",
    "n_qubits = 3  # Increase to accommodate QPE and HHL\n",
    "\n",
    "# Apply PCA to reduce features to match the number of qubits\n",
    "pca = PCA(n_components=n_qubits - 1)  # Use n_qubits - 1 for feature reduction\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "# Define matrix and vector for HHL\n",
    "def get_matrix_and_vector():\n",
    "    # Example matrix A (2x2) and vector b\n",
    "    A = np.array([[1, 2], [3, 4]])\n",
    "    b = np.array([1, 0])  # Example vector\n",
    "    return A, b\n",
    "\n",
    "# Define the QPE circuit\n",
    "dev_qpe = qml.device(\"default.qubit\", wires=3)  # Number of qubits for QPE\n",
    "\n",
    "@qml.qnode(dev_qpe)\n",
    "def qpe_circuit():\n",
    "    # Apply Hadamard gates to the first two qubits\n",
    "    for i in range(2):\n",
    "        Hadamard(wires=i)\n",
    "    \n",
    "    # Apply controlled operations (simulated)\n",
    "    for i in range(2):\n",
    "        CNOT(wires=[i, 2])\n",
    "\n",
    "    # Apply inverse QFT (simplified)\n",
    "    for i in range(2):\n",
    "        RZ(np.pi / 4, wires=i)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "# Define HHL operations\n",
    "dev_hhl = qml.device(\"default.qubit\", wires=3)  # Number of qubits for HHL\n",
    "\n",
    "@qml.qnode(dev_hhl)\n",
    "def hhl_algorithm(params, b):\n",
    "    # Apply AngleEmbedding to vector b\n",
    "    AngleEmbedding(b, wires=[0, 1])\n",
    "\n",
    "    # Apply HHL operations (placeholders here)\n",
    "    for i in range(2):\n",
    "        RX(params[i], wires=i)\n",
    "    \n",
    "    # Simulate controlled rotations (placeholders)\n",
    "    for i in range(2):\n",
    "        RZ(params[i], wires=2)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def solve_linear_system(A, b):\n",
    "    # Perform QPE\n",
    "    qpe_result = qpe_circuit()\n",
    "\n",
    "    # Solve using HHL\n",
    "    params = [np.pi / 4, np.pi / 2]  # Example parameters\n",
    "    return hhl_algorithm(params, b)\n",
    "\n",
    "def get_predictions(X):\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        A, b = get_matrix_and_vector()  # Get matrix A and vector b\n",
    "        pred = solve_linear_system(A, x)\n",
    "        predictions.append(pred)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Generate predictions\n",
    "y_train_pred = get_predictions(X_train_reduced)\n",
    "y_test_pred = get_predictions(X_test_reduced)\n",
    "\n",
    "# Define an anomaly threshold\n",
    "threshold = np.percentile(y_train_pred, 95)  # Example threshold\n",
    "\n",
    "# Identify anomalies\n",
    "train_anomalies = y_train_pred > threshold\n",
    "test_anomalies = y_test_pred > threshold\n",
    "\n",
    "# Attach confidence scores\n",
    "train_confidence = y_train_pred[train_anomalies]\n",
    "test_confidence = y_test_pred[test_anomalies]\n",
    "\n",
    "# Get latitude and longitude for anomalies\n",
    "train_anomalies_lat_lon = lat_train[train_anomalies]\n",
    "test_anomalies_lat_lon = lat_test[test_anomalies]\n",
    "\n",
    "# Debugging: Print lengths to ensure they match\n",
    "print(f\"Train anomalies latitude/longitude shape: {train_anomalies_lat_lon.shape}\")\n",
    "print(f\"Train confidence shape: {train_confidence.shape}\")\n",
    "print(f\"Test anomalies latitude/longitude shape: {test_anomalies_lat_lon.shape}\")\n",
    "print(f\"Test confidence shape: {test_confidence.shape}\")\n",
    "\n",
    "# Print anomalies and their confidence scores\n",
    "print(\"Train anomalies:\")\n",
    "for i, (lat_lon, conf) in enumerate(zip(train_anomalies_lat_lon, train_confidence)):\n",
    "    lat, lon = lat_lon\n",
    "    print(f\"Anomaly {i + 1}: Latitude={lat}, Longitude={lon}, Confidence={conf:.4f}\")\n",
    "\n",
    "print(\"\\nTest anomalies:\")\n",
    "for i, (lat_lon, conf) in enumerate(zip(test_anomalies_lat_lon, test_confidence)):\n",
    "    lat, lon = lat_lon\n",
    "    print(f\"Anomaly {i + 1}: Latitude={lat}, Longitude={lon}, Confidence={conf:.4f}\")\n",
    "\n",
    "# Measure execution time\n",
    "print(f\"\\nExecution time: {time.time() - start:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09a2343d96e4209a5eb8971e1e9a0248c4f95d560a06ad86d050590524a525f8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
